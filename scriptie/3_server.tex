\part{Server}
\label{server}

\chapter{Structuur}
\label{server:structuur}

Op het hoogste niveau hebben we de serverapplicatie onderverdeeld in enkele logische subsystemen, zijnde het netwerk en de repository. Onderling communiceren deze subsystemen niet met elkaar: coördinatie verloopt door een overkoepelende controller. Zo is het mogelijk om elk subsysteem als een alleenstaand geheel te behandelen, wat het ontwikkelingsproces sterk vereenvoudigt. Tenslotte is er nog de webinterface, die dezelfde visibiliteit heeft als de controller: acties die een gebruiker uitvoert op de beheerinterface kunnen een impact hebben op objecten binnen het netwerk of de repository.

Om code te abstraheren en controle van subsystemen te vereenvoudigen moet elk van de subsystemen een bepaalde klasse uitbreiden met de concrete implementatie. Die klasse voorziet niet alleen in bepaalde gedeelde functionaliteit (zoals het genereren van log berichten, of inladen van de nodige configuratiebestanden), maar schrijft ook voor hoe de effectieve implementatie moet gevormd worden. Hierdoor wordt het eenvoudig om vanuit de applicatiecontroller op een eenduidige manier bepaalde standaardacties (zoals het opstarten of afsluiten van een subsysteem) uit te voeren.

\section{Netwerk subsysteem}
\label{server:structuur:netwerk}

Het netwerk subsysteem verzorgt wat we in de vorige hoofdstukken tot applicatieprotocol gedoopt hebben. Het subsysteem is opgesplitst in enkele samenwerkende componenten: vooreerst is er het gedeelte dat dient als main entrypoint voor andere componenten die willen gebruik maken van het netwerksubsysteem. Daartoe biedt het bijvoorbeeld een lijst van aanwezige kiosken, en kan voor elke kiosk een object opgevraagd worden dat toelaat om gegevens op te halen of acties uit te voeren. Ook is er voorzien in de nodige functionaliteit om signalen door te geven, bijvoorbeeld om geschikt te reageren op de toevoeging van een nieuwe kiosk.
Door al deze functionaliteit te bundelen in een enkele klasse, is dit de enige interface tussen het volledige subsysteem en de rest van de applicaties. De uiteindelijke implementatie van het subsysteem kan hierdoor eenvoudig gewijzigd worden, zonder veel te moeten veranderen aan componenten die gebruik maken van dit systeem.

Het netwerk subsysteem bevat ook nog een gedeelte dat instaat voor de effectieve monitoring van het netwerk, door te reageren op signalen van de achterliggende \ac{upnp} bibliotheek. Dit gedeelte is puur intern, en het is niet de bedoeling dat een externe component communiceert met deze netwerk monitor. Als de monitor bepaalde informatie wil vrijgeven aan de buitenwereld (wat bijvoorbeeld voorkomt als het een nieuwe kiosk detecteert), zal het dit doorgeven aan de publieke component van het netwerk subsysteem, waarna die bijvoorbeeld bepaalde signalen zal uitsturen. Hoewel dit geconvolueerd mag lijken is dit een heel interessant design: zoals hierboven vermeld mogen we nu steeds de monitor naar believen aanpassen; zolang de publieke interface maar dezelfde blijft zal niemand hier iets merken.

Om het voor de buitenwereld eenvoudig te maken om te interfacen met het netwerk, zal de publieke interface niet alleen informatie vrijgeven maar ook toegang bieden tot functionele objecten die eenvoudige manipulatie van hun onderwerp toelaten. Zo zal een \code{Network::getDevice(String uuid)} aanroep niet louter informatie over het toestel teruggeven, maar een volwaardig \code{Device} object. Dit object kan dan gebruikt worden om het toestel zelf te manipuleren: indien we bijvoorbeeld over een kiosk spreken zal het voorzien zijn van een \code{Device::Shutdown} methode.

\section{Repository subsysteem}
\label{server:structuur:repository}

Dit systeem dient als wrapper rond de repository waarbinnen alle gegevens van het systeem (configuraties en voorstellingen) opgeslagen zijn. Zoals vermeld in hoofdstuk \ref{ontwerp} staat de server in voor het ophalen en verwerken van de configuratiegegevens, en moet het de nodige kiosken laten weten wanneer de media die ze tonen gewijzigd zijn.

Net zoals bij het netwerk subsysteem biedt het repository subsysteem een publieke interface die de buitenwereld toelaat gegevens op te vragen. Ook zullen de teruggegeven objecten opnieuw gesofisticeerd zijn om eenvoudig verwerken van de gegevens toe te laten: de \code{Repository::getConfiguration(String id)} aanroep bijvoorbeeld zal daarom een \code{KioskConfiguration} object teruggeven hetwelk specifieke functies bevat zoals \code{getVolume}. Hoewel dit systeem zijn nadelen kent -- een wijziging van het configuratieformaat vereist direct wijzigingen aan de servercode -- zorgt de rigide opzet ervoor dat inconsistenties tussen de repository en de achterliggende logica snel zullen duidelijk worden. 

Bij het opstarten van het repository subsysteem zal een initiële \code{checkout} uitgevoerd worden. Hierna zal een interne timer gestart worden die om de minuut controleert of er geen nieuwe revisie in de repository te vinden is. Indien dat het geval is, zullen alle configuraties opnieuw binnengehaald worden om dan eventueel de wijzigingen naar een client te sturen. Momenteel gebeurt dit echter vrij inefficiënt: alle configuraties worden opnieuw opgehaald en verstuurd, los van het feit of er ook effectief wijzigingen gebeurd zijn. Voor een volgende versie streven we ernaar om ook effectief de delta-gegevens te interpreteren en zo intelligent de nodige veranderingen door te sturen.

\section{Applicatiecontroller}
\label{server:structuur:controller}

Dit systeem staat in voor de coördinatie van acties die niet geïsoleerd blijven tot een enkel subsysteem. Het beste voorbeeld hiervoor is wanneer het netwerk subsysteem een nieuwe component detecteert. Om de code overzichtelijk te houden zal het netwerk subsysteem dan geen actie ondernemen, maar louter zijn gegevens updaten en een signaal uitsturen. De applicatiecontroller vangt tenslotte dit signaal op om vervolgens de repository te raadplegen voor eventuele configuratiegegevens.

\section{Website subsysteem}
\label{server:structuur:website}

Deze component visualiseert de gegevens uit de repository en netwerk subsystemen, en laat de gebruiker toe om er controle over uit te oefenen. Die controle is echter beperkt: persistente configuratie moet nog altijd verlopen via manuele interventie.

\chapter{Realisatie}
\label{server:realisatie}

\section{Statische codeanalyse}
\label{server:realisatie:codeanalyse}

Om de kwaliteit van de code systematisch op te drijven, hebben we gebruik gemaakt van statische codeanalyse. Daarbij analyseert een applicatie de code zonder die ook effectief uit te voeren, om vervolgens een verslag te kunnen opbouwen waarbij de inhoud verschilt van applicatie tot applicatie.

\subsection{Stijl}
\label{server:realisatie:codeanalyse:stijl}

Een eerste soort van statische codeanalyse-applicaties toetst de codebase aan een verzameling regels om zo een uniforme codestijl te bekomen. Dit lijkt misschien niet zo nuttig, maar leesbare code en een uniforme codestijl maakt het veel eenvoudiger om de applicatie te onderhouden.
Voor Java bestaat er zo een heel krachtige applicatie, \makeurl{http://checkstyle.sourceforge.net/}{Checkstyle}, die geleverd wordt met een enorm uitgebreide set aan modules die elk een bepaald aspect analyseren. Om nog verfijnder tewerk te gaan kunnen we elke module vaak beperken met een aantal filters, zodat we bijvoorbeeld eenvoudig kunnen stellen dat de publieke methodes van een interface voorzien moeten zijn van Javadoc.

De standaardconfiguratie van Checkstyle is vrij strikt, waardoor een eerste controle van de serverapplicatie meer dan 1500 waarschuwingen opleverde. Daarom hebben we een eigen configuratie aangemaakt, gebaseerd op de standaardconfiguratie met de strengste eisen (zoals het beperken van de lijnlengte, of het verbieden van elk teveel aan spaties) wat versoepeld. Ook hebben we enkele eigen regels toegevoegd om praktijken die we reeds uitvoerden nu ook systematisch te kunnen controleren. Zo hebben we bijvoorbeeld een regel toegevoegd die bepaalt dat variabelen binnen een klasse geprefixt moeten worden met een kleine ``m'', parameters van een functie een ``i'' voor hun naam moeten krijgen, en lokale variabelen altijd met een ``t'' moeten beginnen. De configuratie van die ene regel is te zien in fragment \ref{lst:checkstyle:variabelen}.

\begin{lstlisting}[language=XML, float, caption="Checkstyle configuratie voor de naamgeving van variabelen., label=lst:checkstyle:variabelen]
<module name="LocalVariableName">
  <property name="format" value="^t[A-Z][a-zA-Z0-9]*$"/>
</module>
<module name="ParameterName">
  <property name="format" value="^i[A-Z][a-zA-Z0-9]*$"/>
</module>
<module name="MemberName">
  <property name="format" value="^m[A-Z][a-zA-Z0-9]*$"/>
</module>
\end{lstlisting}

\subsection{Correctheid}
\label{server:realisatie:codeanalyse:correctheid}

Dergelijke applicaties gaan op zoek naar logische fouten in de code, waarbij de code wel legaal is maar ze bijvoorbeeld de applicatie doet crashen wanneer ze uitgevoerd wordt. Het is duidelijk dat dit een zeer complexe definitie is, die veel gesoftisticeerdere regels en heuristieken vereist dan wanneer men louter de codestijl wil controleren. Het probleem met zulke applicaties is dan ook dat er vaak een lage \emph{signal to noise} verhouding is: of er worden veel valse positieven gedetecteerd, of veel fouten worden helemaal niet gevonden.

Om toch zoveel mogelijk fouten te vinden via statische analyse, hebben we gebruik gemaakt van meerdere tools. Vooreerst hebben we gekeken naar \makeurl{http://findbugs.sourceforge.net/}{FindBugs}, een tool die zoals de naam laat uitschijnen vooral op zoek gaat naar echte fouten. Hoewel de \makeurl{http://findbugs.sourceforge.net/bugDescriptions.html}{databank aan regels} die het daarbij gebruikt vrij uitgebreid is, had FindBugs niet veel te zeggen over onze code. We hopen dat dit een teken is dat de codebase van goede kwaliteit is.

Een andere applicatie die we gebruikt hebben is \makeurl{http://pmd.sourceforge.net/}{PMD}. Deze gaat niet alleen op zoek naar bugs, maar ook naar verkeerd gebruik van geheugen, overdreven complexe codefragmenten, suboptimale code, en code die nooit uitgevoerd wordt (\emph{dead code}). Zo hebben we met behulp van PMD verschillende suboptimale \emph{inner loops} kunnen versnellen, alsook enkele complexe klassen vereenvoudigd. Kritieke fouten zijn er echter opnieuw niet gevonden.

\chapter{Deployment}
\label{server:deployment}

\section{Besturingssysteem}
\label{server:deployment:besturingssysteem}

Zoals wel vaker het geval is, is de keuze van het besturingssysteem beperkt geweest door de hardware waarop het moest draaien. Zo komt de Synology DS207+ wel met een Linux-distributie, maar is die zodanig geconfigureerd dat we eigenlijk liever zouden uitwijken naar een meer \emph{general purpose} embedded distributie. Hierbij denken we bijvoorbeeld aan de vele foto-, muziek- en videoapplicaties die standaard op het toestel staan, of aan de zeer mooie maar even nutteloze webinterface die het toestel aanbiedt.

Maar zomaar even een andere distributie installeren is helemaal niet zo eenvoudig. Omdat het hier om een zeer specifiek toestel met beperkte hardware gaat, kunnen we bijvoorbeeld niet van een CD-image opstarten om Debian of Fedora te installeren: of we moeten direct de geheugenchips herprogrammeren, of we moeten een manier vinden om een image te maken die compatibel is met de upgrade-wizard in de webinterface. Het mag duidelijk zijn dat dit geen sinecure is die de tijdsplanning van het project zou hypothekeren.

Het alternatief, verder werken met het standaard besturingssysteem, was anderzijds ook niet altijd eenvoudig. Een groot probleem was de incompatibiliteit met reeds gecompileerde programma's, dat zijn oorsprong kent in de processor die in het toestel zit: de Marvell MV5281, een \ac{arm} gebaseerde processor. Deze ondersteunt immers twee instructiesets, elk corresponderend met een aparte \acp{abi} voor programma's: de \ac{oabi} en de nieuwere \ac{eabi}. Die laatste is geoptimaliseerd voor embedded devices en kent veel voordelen: zo zijn floating-point bewerkingen sneller, is het eenvoudiger om \code{struct}s te verpakken, en kunnen systeemaanroepen efficiënter uitgevoerd worden \citep{linuxfordevices:eabi}.

Door deze duidelijke voordelen zijn vrijwel alle grote Linux-distributies (zoals Fedora, Red-Hat, of Ångström) al verschillende jaren overgeschakeld naar de \ac{eabi}. Jammer genoeg is dit niet het geval voor de distributie op de Synology, waardoor we geen gebruik kunnen maken van bestaande repositories aan gecompileerde programma's. Meer nog, bepaalde programma's die gebruik maken van zorgvuldig geoptimaliseerde low-level code zullen helemaal niet werken op onze Linux-installatie, zelfs als we ze hercompileren om te werken onder de \ac{oabi}!

Dit was bijvoorbeeld het geval met OpenJDK, de meest gebruikte open-source implementatie van de Java programmeertaal. Deze is voor \ac{arm} processoren enkel beschikbaar voor de \ac{eabi}, voor een \ac{oabi} versie is er nog nood aan een gepaste \ac{jit} compiler die met deze instructieset overweg kan \citep{synology:java}. Daarom hebben we gebruik gemaakt van \makeurl{http://jamvm.sourceforge.net/}{JamVM}: een compactere \ac{jvm}, zonder alle complexe machine-gebonden optimalisaties, die wel kan gecompileerd worden tegen de \ac{oabi}. Een gevolg is wel dat we niet gebruik kunnen maken van de OpenJDK libraries, maar zullen gebruik moeten maken van \makeurl{https://www.gnu.org/s/classpath/}{\acs{gnu} Classpath}, een alternatieve implementatie van die libraries.

Maar Classpath bleek geen volwaardig alternatief te zijn: verschillende aspecten van de Java \ac{api} zijn er niet in geïmplementeerd. En ook JamVM blijft op bepaalde vlakken in gebreke, zo kan het enkel Java Bytecode verwerken die voldoet aan versie 1.5 van de Java specificatie, en blijkt de rudimantaire \ac{jit} die het aan boord heeft toch wel zeer traag te werken. Op dit moment hebben we aan met deze beperkingen rekening gehouden door het gebruik van enkele ``geavanceerde'' Java features achterwege te laten, en enkele libraries in te wisselen met een alternatief dat voldoende heeft aan Java 1.5, maar op termijn gaan we toch proberen een volwaardige \ac{jre} op het toestel te installeren of indien dat niet lukt op zoek gaan naar nieuwe hardware.

\section{Versioning}
\label{server:deployment:versioning}

We hebben gekozen om de code en andere relevante bestanden te bewaren met behulp van Git, een populair broncode management systeem. Een van de voordelen van Git is dat het gedistribueerd is: elke \emph{checkout} bevat de hele geschiedenis van het project, en het is mogelijk om code van de ene checkout naar de andere te \emph{pushen} of \emph{pullen}. Er is met andere woorden geen centrale server in het spel, waardoor er geen single point of failure meer is.

Hoewel er verschillende gedistribueerde versiebeheersystemen bestaan, hebben we dankzij eerdere ervaring alsook de beschikbaarheid van gratis servers om een Git-repository op te hosten (zoals \makeurl{https://github.com/}{GitHub}) gekozen voor Git. Dergelijke hosting servers zijn in principe niet nodig, maar het verhoogt de blootstelling van de code en zorgt ervoor dat er een kopie van het project op een externe server staat waardoor de kans op dataverlies weer zoveel kleiner wordt.

Een sterke eigenschap van Git is dat het heel eenvoudig (en snel) is om een \emph{branch} aan te maken: dit is een afsplitsing van de code waarop men kan werken zonder invloed te hebben op andere branches. Hiermee kunnen we zeer eenvoudig de ontwikkeling splitsen in twee pistes, elk met hun specifiek doel:
\begin{enumerate}
  \item Master branch: hierop gebeurt de ontwikkeling van nieuwe features, die eerst nog grondig moeten getest worden vooraleer in productie te komen;
  \item Stable branch: deze branch bevat grondig geteste code die direct in gebruik mag komen.
\end{enumerate}
Nadat een nieuwe feature op de master branch ontwikkeld is, kunnen we ze nu zo lang testen als we willen zonder daarbij te verhinderen dat we tegelijkertijd fixes doorvoeren aan de code die effectief in gebruik is: door eenvoudig te wisselen naar de stable branch vergeten we tijdelijk alles over de nieuwe features op de master branch. Wanneer vervolgens de feature stabiel geacht wordt, kunnen we de relevante commits pushen naar de stable branch.

\section{Compilatie}
\label{server:deployment:compilatie}

Voor het bouwen van een executable hebben we gebruik gemaakt van \ac{maven}, een softwarebeheersysteem dat op een flexibele manier toelaat om alle aspecten van het bundelen van een applicatie te organiseren. Daartoe voorzien we in een \ac{pom} bestand waarin alle informatie verwerkt zit, zoals de naam en versie van de toepassing, de libraries waarop het berust, en hoe de applicatie moet opgestart worden. Aan de hand van die informatie kan \ac{maven} het project gepast uitvoeren of bundelen tot een finale executable.

Ook wordt het gebruik van externe libraries vereenvoudigt: er bestaat een \ac{maven} repository met daarin de meest populaire libraries, waardoor we louter de naam en versie in het \ac{pom} bestand moeten specificeren en \ac{maven} met deze informatie zelf op zoek gaat naar de gepaste binaries die benodigd zijn om de applicatie op te starten (zie bijvoorbeeld fragment \ref{lst:maven}).

\begin{lstlisting}[language=XML, float, caption=Inladen van externe libraries via Maven., label=lst:maven]
<dependencies>
  <dependency>
    <groupId>log4j</groupId>
    <artifactId>log4j</artifactId>
  </dependency>
  ...
</dependencies>
\end{lstlisting}

Voor enkele libraries die we niet terugvonden in de officiële \ac{maven} repositories hebben we ofwel een alternatieve repository toegevoegd die het pakket wel bevatte (zoals dat was in het geval van Cling), of zelf voorzien in een lokale repository die de benodigde bestanden bevat en gebundeld is met de broncode om iedereen toe te laten de applicatie zonder al te veel moeite te compileren.

Ook kent \ac{maven} een plugin-systeem, dat we dankbaar gebruiken om bepaalde specifieke taken uit te voeren. Zo willen we bijvoorbeeld een \ac{jar} bestand genereren dat tegelijk alle afhankelijke libraries bevat, om zo installatie op de uiteindelijke server te vereenvoudigen. Dit druist deels in tegen de ideale manier om software te packagen, waarbij externe libraries steeds via de lokale package-manager geïnstalleerd worden, maar omdat we daarvoor zeer nauwgezet het pakket zouden moeten onderhouden (updates van een externe library kan immers steeds problemen veroorzaken in de applicatie zelf) hebben we ervoor gekozen om alles tezamen te bundelen tot een monolitisch geheel. Dit is ook de norm binnen de Java-wereld. Specifiek voor de serverapplicatie is de relevante configuratie daarvoor te vinden in fragment \ref{lst:fatjar}.

\begin{lstlisting}[language=XML, float, caption=Gebruik van Maven modules om een executable te compileren., label=lst:fatjar]
<build>
  <plugins>
    <plugin>
    <groupId>org.apache.maven.plugins</groupId>
    <artifactId>maven-assembly-plugin</artifactId>
    <executions>
      <execution>
        <id>package-jar-with-dependencies</id>
        <phase>package</phase>
        <goals>
          <goal>single</goal>
        </goals>
        <configuration>
          <appendAssemblyId>false</appendAssemblyId>
          <descriptorRefs>
            <descriptorRef>
              jar-with-dependencies
            </descriptorRef>
          </descriptorRefs>
          <archive>
            <manifest>
              <mainClass>
                be.mira.adastra3.server.Main
              </mainClass>
            </manifest>
          </archive>
        </configuration>
      </execution>
    </executions>
  </plugin>
</build>
\end{lstlisting}

Een andere plugin die we gebruikt hebben is de ``site plugin'', waarmee we tijdens het compileren een website kunnen genereren. Afhankelijk van welke reporting-plugins we inschakelen, zal deze site bijvoorbeeld een pagina met informatie over het project bevatten, of een overzicht van alle klassen aanbieden. Een andere mogelijkheid is om de verslagen gegenereerd door verschillende codeanalyse tools overzichtelijk weer te geven, waardoor het eenvoudiger is om de resultaten van de analyse te verwerken. Jammer genoeg bestaan er niet voor alle codeanalyse tools Maven plugins die de output ervan kunnen verwerken, maar voor de tools die wij geselecteerd hebben in sectie \ref{server:realisatie:codeanalyse} bestonden de nodige plugins gelukkig wel. Een voorbeeld van hoe we dit geconfigureerd hebben voor de Checkstyle tool is te vinden in fragment \ref{lst:maven:reporting}.

\begin{lstlisting}[language=XML, float, caption=Configuratie van de Maven site plugin voor het genereren van Checkstyle reports., label=lst:maven:reporting]
<plugin>
  <groupId>org.apache.maven.plugins</groupId>
  <artifactId>maven-site-plugin</artifactId>
  <configuration>
    <reportPlugins>
      <plugin>
        <artifactId>maven-checkstyle-plugin</artifactId>
        <configuration>
          <configLocation>checkstyle.xml</configLocation>
        </configuration>
      </plugin>
      <...>
    </reportPlugins>
  </configuration>
</plugin>
\end{lstlisting}

\section{Repository}
\label{server:deployment:repository}

Zoals beschreven in hoofdstuk \ref{ontwerp:applicatie} hebben we wegens problemen met de serverside-bindings ervoor moeten kiezen om gebruik te maken van een externe \ac{svn} repository. In eerste instantie hadden we dat gedaan door een overkoepelende Apache webserver op te stellen, waarbij het eenvoudig mogelijk is om een \ac{svn} repository te hosten via de \code{mod\_dav} \ac{webdav} module. Om dan wel geen twee webservers draaiende te hebben (onze applicatie heeft immers ook nog een embedded Tomcat servlet engine aan boord), hadden we dan gebruik gemaakt van de \code{mod\_jk} Tomcat Apache Connector om te serverapplicatie te laten overkoepelen door Apache. Daarbij wordt de communicatie tussen beide applicaties verzorgt over het binaire \ac{ajp} protocol, waardoor het mogelijk is om communicatie met zowel de Tomcat servlet-engine als de door Apache beheerde \ac{svn} repository over dezelfde poort te laten.

Maar dit was maar een geconvolueerd systeemn, en \ac{webdav} bleek ook niet de meest efficiënte overdrachtsmodus te zijn die \ac{svn} ondersteunt. Daarom hebben we er uiteindelijk voor gekozen om \code{svnserve} te gebruiken, die communicatie verzorgt over een binair protocol dat zeker op low-latency \ac{lan} netwerken een veel betere performantie bleek te hebben. Hierbij verviel de nood aan een Apache webserver, en de bijhorende Tomcat Apache Connector. De configuratie van \code{svnserve} (te zien in fragment \ref{lst:svnserve}) was uiteindelijk ook niet al te moeilijk, en zeker niet complexer dan de samengestelde configuratie van alle componenten die in de eerste opzet benodigd waren.

\begin{lstlisting}[float, caption=Configuratie van een door svnserve-beheerde \acs{svn} repository., label=lst:svnserve]
[general]
anon-access = none
auth-access = write
password-db = passwd
realm = Ad-Astra III - Data repository

[sasl]
use-sasl = true
min-encryption = 1
max-encryption = 256
\end{lstlisting}

Zoals in fragment \ref{lst:svnserve} te zien is maken we gebruik van \ac{sasl}, waardoor we op een eenvoudige manier kunnen gebruik maken van een robuust authenticatiemechanisme voor dataoverdracht van en naar de \ac{svn} repository. Hoewel dit als nadeel heeft dat anonieme toegang tot de repository, wat we (natuurlijk \emph{read-only}) zouden gebruikt hebben voor de kiosken bestanden te laten ophalen, biedt het een zeer groot voordeel: encryptie en integriteitscontrole. Door de \code{min-encryption} instelling op $1$ te zetten, verplichten we dat alle communicatie tenminste onderworpen wordt aan een integriteitscontrole, terwijl de \code{max-encryption} instelling ervoor zorgt dat het wel mogelijk blijft om volledige encryptie toe te passen. Hierdoor wordt het onmogelijk om de data te vervalsen, en worden de gebruikersnamen en wachtwoorden die het mogelijk maken om de data te wijzigen beschermd door de encryptie die \ac{sasl} biedt.
